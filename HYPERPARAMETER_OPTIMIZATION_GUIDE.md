# ğŸ¯ Hyperparameter Optimization Guide

## Overview

This guide explains how to optimize all models in your project using Optuna, a state-of-the-art hyperparameter optimization framework.

---

## ğŸš€ Quick Start

### Step 1: Install Optuna
```bash
pip install optuna
```

### Step 2: Run Optimization
```bash
cd models
python hyperparameter_optimization.py
```

This will:
- Optimize Random Forest (30 trials, ~30 minutes)
- Optimize XGBoost (30 trials, ~45 minutes)
- Optimize TabTransformer (15 trials, ~2-3 hours)
- Generate comparison reports

### Step 3: Update Dashboard
```bash
python update_dashboard_with_optimized.py
```

### Step 4: Restart Dashboard
```bash
cd ..
streamlit run app.py
```

---

## ğŸ“Š What Gets Optimized?

### Random Forest
```python
Hyperparameters:
â”œâ”€â”€ n_estimators: 50-300 (number of trees)
â”œâ”€â”€ max_depth: 10-50 (tree depth)
â”œâ”€â”€ min_samples_split: 2-20
â”œâ”€â”€ min_samples_leaf: 1-10
â”œâ”€â”€ max_features: ['sqrt', 'log2', None]
â””â”€â”€ class_weight: ['balanced', 'balanced_subsample']

Search Space: ~1,000,000 combinations
Trials: 30 (samples best combinations)
Time: ~30 minutes
```

### XGBoost
```python
Hyperparameters:
â”œâ”€â”€ n_estimators: 100-500 (number of boosting rounds)
â”œâ”€â”€ learning_rate: 0.01-0.3 (step size)
â”œâ”€â”€ max_depth: 3-15 (tree depth)
â”œâ”€â”€ subsample: 0.6-1.0 (data sampling)
â”œâ”€â”€ colsample_bytree: 0.6-1.0 (feature sampling)
â”œâ”€â”€ reg_alpha: 0-1.0 (L1 regularization)
â”œâ”€â”€ reg_lambda: 0-2.0 (L2 regularization)
â”œâ”€â”€ min_child_weight: 1-10
â””â”€â”€ gamma: 0-1.0 (minimum loss reduction)

Search Space: ~10,000,000 combinations
Trials: 30
Time: ~45 minutes
```

### TabTransformer
```python
Hyperparameters:
â”œâ”€â”€ d_model: [32, 64, 128] (embedding dimension)
â”œâ”€â”€ num_heads: [2, 4, 8] (attention heads)
â”œâ”€â”€ num_layers: 2-4 (transformer blocks)
â”œâ”€â”€ d_ff: [64, 128, 256] (feed-forward dimension)
â”œâ”€â”€ dropout: 0.1-0.3 (regularization)
â”œâ”€â”€ embedding_dim: [8, 16, 32] (categorical embeddings)
â”œâ”€â”€ learning_rate: 0.0001-0.01 (optimizer step size)
â””â”€â”€ batch_size: [64, 128, 256] (training batch size)

Search Space: ~100,000 combinations
Trials: 15 (fewer due to training time)
Time: ~2-3 hours
```

---

## ğŸ”¬ How Optuna Works

### 1. Bayesian Optimization
```
Traditional Grid Search:
â”œâ”€â”€ Try ALL combinations (exhaustive)
â”œâ”€â”€ Time: Days/weeks for large spaces
â””â”€â”€ Inefficient

Optuna (Bayesian):
â”œâ”€â”€ Try smart combinations (guided by previous results)
â”œâ”€â”€ Time: Hours
â”œâ”€â”€ Learns which areas are promising
â””â”€â”€ Efficient
```

### 2. Trial Process
```
For each trial:
1. Optuna suggests hyperparameters
2. Train model with those parameters
3. Evaluate on validation set
4. Report score back to Optuna
5. Optuna learns and suggests better parameters
6. Repeat

After all trials:
â†’ Best parameters found!
```

### 3. Visualization
```
Optuna tracks:
â”œâ”€â”€ Best score over time
â”œâ”€â”€ Parameter importance
â”œâ”€â”€ Optimization history
â””â”€â”€ Parallel coordinate plots
```

---

## ğŸ“ˆ Expected Improvements

### Based on Typical Results

```
Random Forest:
â”œâ”€â”€ Baseline: 21.64%
â”œâ”€â”€ Expected Optimized: 25-30%
â””â”€â”€ Improvement: +15-40%

XGBoost:
â”œâ”€â”€ Baseline: ~40% (needs retraining)
â”œâ”€â”€ Expected Optimized: 45-50%
â””â”€â”€ Improvement: +10-25%

TabTransformer:
â”œâ”€â”€ Baseline: 44.97%
â”œâ”€â”€ Expected Optimized: 48-52%
â””â”€â”€ Improvement: +5-15%
```

**Note:** Deep learning models (TabTransformer) typically show smaller improvements because they're already well-tuned. Traditional ML models often show larger gains.

---

## ğŸ¯ Optimization Strategy

### What Optuna Does

1. **Exploration Phase (First 10 trials)**
   - Tries diverse parameter combinations
   - Explores the search space
   - Identifies promising regions

2. **Exploitation Phase (Remaining trials)**
   - Focuses on best-performing regions
   - Fine-tunes parameters
   - Converges to optimal values

3. **Final Selection**
   - Returns best parameters found
   - Trains final model with those parameters
   - Evaluates on test set

---

## ğŸ“ Output Files

### After Optimization

```
models/
â”œâ”€â”€ rf_optimized.pkl              â† Optimized Random Forest
â”œâ”€â”€ xgb_optimized.pkl             â† Optimized XGBoost
â”œâ”€â”€ tab_transformer_optimized.pth â† Optimized TabTransformer
â”œâ”€â”€ optimization_results.csv      â† Summary table
â”œâ”€â”€ optimization_results_detailed.txt â† Full details
â””â”€â”€ optimization_metrics.json     â† For dashboard display
```

### Results Format

**optimization_results.csv:**
```csv
Model,Baseline Accuracy,Optimized Accuracy,Improvement (%)
Random Forest,0.2164,0.2850,+31.70%
XGBoost,0.4200,0.4850,+15.48%
TabTransformer,0.4497,0.4920,+9.41%
```

**optimization_results_detailed.txt:**
```
Random Forest:
  Baseline Accuracy: 0.2164
  Optimized Accuracy: 0.2850
  Improvement: +31.70%
  Best Parameters:
    n_estimators: 250
    max_depth: 35
    min_samples_split: 5
    min_samples_leaf: 2
    max_features: sqrt
    class_weight: balanced
```

---

## ğŸ¨ Dashboard Integration

### Before Optimization
```
Model: Random Forest (SKLEARN)
â”œâ”€â”€ Collision Accuracy: 21.64%
â”œâ”€â”€ Severity Accuracy: N/A
â””â”€â”€ Overall F1: 0.180
```

### After Optimization
```
Model: Random Forest (SKLEARN)
ğŸ¯ Optimized Model - Hyperparameters tuned with Optuna

â”œâ”€â”€ Baseline Accuracy: 21.64%
â”œâ”€â”€ Optimized Accuracy: 28.50%
â”œâ”€â”€ Improvement: +31.70% â†‘
â””â”€â”€ F1-Score: 0.245
```

---

## âš™ï¸ Advanced Usage

### Custom Number of Trials

```python
# Quick optimization (fewer trials)
optimizer.train_random_forest(n_trials=10)  # ~10 minutes
optimizer.train_xgboost(n_trials=10)        # ~15 minutes
optimizer.train_tabtransformer(n_trials=5)  # ~1 hour

# Thorough optimization (more trials)
optimizer.train_random_forest(n_trials=50)  # ~50 minutes
optimizer.train_xgboost(n_trials=50)        # ~75 minutes
optimizer.train_tabtransformer(n_trials=30) # ~6 hours
```

### Optimize Single Model

```python
from hyperparameter_optimization import ModelOptimizer

optimizer = ModelOptimizer(data_path='../data/model_ready.csv')

# Optimize only Random Forest
optimizer.train_random_forest(n_trials=30)
optimizer.generate_report()
```

### Resume Optimization

```python
# Optuna can resume from previous studies
study = optuna.load_study(
    study_name='rf_optimization',
    storage='sqlite:///optuna.db'
)
study.optimize(objective, n_trials=20)  # Continue optimization
```

---

## ğŸ” Understanding the Results

### Metrics Explained

**Accuracy:**
- Percentage of correct predictions
- Higher is better
- Your data: 8 classes, so random = 12.5%

**F1-Score:**
- Harmonic mean of precision and recall
- Balances false positives and false negatives
- Range: 0-1, higher is better

**Improvement %:**
- Relative improvement over baseline
- Formula: (optimized - baseline) / baseline Ã— 100
- Example: 21.64% â†’ 28.50% = +31.70% improvement

### What's a Good Improvement?

```
Improvement Range:
â”œâ”€â”€ 0-5%:   Small (but still valuable)
â”œâ”€â”€ 5-15%:  Moderate (good optimization)
â”œâ”€â”€ 15-30%: Large (excellent optimization)
â””â”€â”€ 30%+:   Exceptional (rare, usually means baseline was poor)
```

---

## ğŸš¨ Troubleshooting

### Issue: Optimization is too slow

**Solution 1:** Reduce trials
```python
optimizer.train_tabtransformer(n_trials=5)  # Instead of 15
```

**Solution 2:** Use smaller data subset
```python
# Edit hyperparameter_optimization.py
subset_size = min(20000, len(y))  # Instead of 50000
```

**Solution 3:** Reduce epochs for TabTransformer
```python
# In optimize_tabtransformer function
epochs=5  # Instead of 10
```

### Issue: Out of memory

**Solution:** Reduce batch size
```python
# TabTransformer will automatically try smaller batches
# Or manually set in optimization:
batch_size = trial.suggest_categorical('batch_size', [32, 64])
```

### Issue: No improvement

**Possible reasons:**
1. Model already well-tuned (TabTransformer case)
2. Need more trials (try 50+ trials)
3. Search space too narrow (expand ranges)
4. Data quality issues (check preprocessing)

---

## ğŸ“š Technical Details

### Cross-Validation

```python
# 3-fold cross-validation used during optimization
scores = cross_val_score(model, X_train, y_train, cv=3)

Why 3-fold?
â”œâ”€â”€ Faster than 5-fold or 10-fold
â”œâ”€â”€ Still provides good estimate
â””â”€â”€ Balances speed vs accuracy
```

### Scoring Metric

```python
# Accuracy used as optimization metric
scoring='accuracy'

Why accuracy?
â”œâ”€â”€ Simple and interpretable
â”œâ”€â”€ Appropriate for multi-class classification
â”œâ”€â”€ Matches your evaluation metric
```

### Random State

```python
random_state=42

Why fixed seed?
â”œâ”€â”€ Reproducible results
â”œâ”€â”€ Fair comparison between trials
â”œâ”€â”€ Consistent baseline
```

---

## ğŸ“ Learning Resources

### Optuna Documentation
- Official docs: https://optuna.readthedocs.io/
- Tutorials: https://optuna.readthedocs.io/en/stable/tutorial/
- Examples: https://github.com/optuna/optuna-examples

### Hyperparameter Tuning
- Scikit-learn guide: https://scikit-learn.org/stable/modules/grid_search.html
- XGBoost tuning: https://xgboost.readthedocs.io/en/stable/tutorials/param_tuning.html
- Deep learning tuning: https://pytorch.org/tutorials/

---

## ğŸ¯ Best Practices

### 1. Start Small
```
First run:
â”œâ”€â”€ 10 trials per model
â”œâ”€â”€ Check if optimization works
â””â”€â”€ Estimate total time

Second run:
â”œâ”€â”€ 30+ trials per model
â”œâ”€â”€ Get better results
â””â”€â”€ Use overnight if needed
```

### 2. Monitor Progress
```
Watch for:
â”œâ”€â”€ Accuracy improving over trials
â”œâ”€â”€ Convergence (scores plateau)
â”œâ”€â”€ Time per trial
â””â”€â”€ Memory usage
```

### 3. Compare Fairly
```
Always:
â”œâ”€â”€ Use same train/test split
â”œâ”€â”€ Use same random seed
â”œâ”€â”€ Use same evaluation metric
â””â”€â”€ Test on held-out test set
```

### 4. Document Results
```
Save:
â”œâ”€â”€ Best parameters
â”œâ”€â”€ Baseline vs optimized scores
â”œâ”€â”€ Training time
â”œâ”€â”€ Date of optimization
â””â”€â”€ Optuna version
```

---

## ğŸ“Š Example Output

### Console Output
```
============================================================
HYPERPARAMETER OPTIMIZATION - ALL MODELS
============================================================

Loading data...
âœ“ Data loaded: 1099868 samples
  Train: 879894, Test: 219974
  Features: 6
  Classes: 8

============================================================
RANDOM FOREST OPTIMIZATION
============================================================

1. Baseline Model (current parameters)...
   Baseline Accuracy: 0.2164
   Baseline F1-Score: 0.1802

2. Optimizing hyperparameters (30 trials)...
[I 2026-02-07 16:30:15] Trial 0 finished with value: 0.2245
[I 2026-02-07 16:31:22] Trial 1 finished with value: 0.2389
[I 2026-02-07 16:32:18] Trial 2 finished with value: 0.2567
...
[I 2026-02-07 16:58:42] Trial 29 finished with value: 0.2834

   Best parameters found:
     n_estimators: 250
     max_depth: 35
     min_samples_split: 5
     min_samples_leaf: 2
     max_features: sqrt
     class_weight: balanced

3. Training optimized model...
   Optimized Accuracy: 0.2850
   Optimized F1-Score: 0.2451

âœ… Improvement: +31.70%
âœ“ Saved to: rf_optimized.pkl

============================================================
OPTIMIZATION RESULTS SUMMARY
============================================================

Model            Baseline Accuracy  Optimized Accuracy  Improvement (%)
Random Forest    0.2164            0.2850              +31.70%
XGBoost          0.4200            0.4850              +15.48%
TabTransformer   0.4497            0.4920              +9.41%

âœ“ Results saved to: optimization_results.csv
âœ“ Detailed results saved to: optimization_results_detailed.txt

============================================================
OPTIMIZATION COMPLETE!
============================================================
```

---

## ğŸ‰ Summary

**What You Get:**
- âœ… Optimized models with better performance
- âœ… Detailed comparison reports
- âœ… Dashboard integration with improvement metrics
- âœ… Best hyperparameters for each model
- âœ… Reproducible optimization process

**Time Investment:**
- Setup: 5 minutes
- Optimization: 3-4 hours (can run overnight)
- Dashboard update: 2 minutes
- **Total: ~4 hours** (mostly automated)

**Expected Results:**
- Random Forest: +15-40% improvement
- XGBoost: +10-25% improvement
- TabTransformer: +5-15% improvement

**Worth It?**
- âœ… Significantly better predictions
- âœ… Professional-grade optimization
- âœ… Impressive for portfolio/presentation
- âœ… Learn advanced ML techniques

**Start optimizing now!** ğŸš€
